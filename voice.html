<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Into MP3 TTS From Images</title>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
  <style>
    body { font-family: sans-serif; background: #111; color: #eee; padding: 2em; text-align: center; }
    input, button { margin: 1em; padding: 0.5em; font-size: 1em; }
    canvas, audio { display: none; }
    #preview { max-width: 100%; margin-top: 1em; border: 2px solid #444; }
    #textOut { white-space: pre-wrap; margin-top: 1em; font-family: monospace; background: #222; padding: 1em; border-radius: 6px; }
  </style>
</head>
<body>
  <h1>ğŸ™ï¸ Into MP3 TTS From Images</h1>
  <p>Upload an image. It extracts the text and converts it to speech. You can export the result as an MP3.</p>
  <input type="file" accept="image/*" id="imgInput">
  <div><img id="preview"></div>
  <div id="textOut"></div>
  <button id="speakBtn">ğŸ”Š Speak</button>
  <button id="exportBtn">ğŸ’¾ Export MP3</button>
  <audio id="audioOut" controls></audio>

  <script>
    const imgInput = document.getElementById('imgInput');
    const preview = document.getElementById('preview');
    const textOut = document.getElementById('textOut');
    const speakBtn = document.getElementById('speakBtn');
    const exportBtn = document.getElementById('exportBtn');
    const audioOut = document.getElementById('audioOut');

    let extractedText = '';

    imgInput.addEventListener('change', e => {
      const file = e.target.files[0];
      if (!file) return;
      const reader = new FileReader();
      reader.onload = () => {
        preview.src = reader.result;
        preview.style.display = 'block';
        Tesseract.recognize(reader.result, 'eng').then(({ data: { text } }) => {
          extractedText = text.trim();
          textOut.textContent = extractedText || '[No text detected]';
        });
      };
      reader.readAsDataURL(file);
    });

    speakBtn.addEventListener('click', () => {
      if (!extractedText) return;
      const utter = new SpeechSynthesisUtterance(extractedText);
      utter.voice = speechSynthesis.getVoices().find(v => v.name.includes('Sam')) || null;
      utter.rate = 1;
      utter.pitch = 1;
      speechSynthesis.speak(utter);
    });

    exportBtn.addEventListener('click', async () => {
      if (!extractedText) return;

      const synth = window.speechSynthesis;
      const utter = new SpeechSynthesisUtterance(extractedText);
      utter.voice = synth.getVoices().find(v => v.name.includes('Sam')) || null;
      utter.rate = 1;
      utter.pitch = 1;

      const audioCtx = new AudioContext();
      const oscillator = audioCtx.createOscillator(); // dummy source
      const dest = audioCtx.createMediaStreamDestination();
      const source = audioCtx.createMediaStreamSource(dest.stream);
      const recorder = new MediaRecorder(dest.stream);
      const chunks = [];

      recorder.ondataavailable = e => chunks.push(e.data);
      recorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        const url = URL.createObjectURL(blob);
        audioOut.src = url;
        audioOut.style.display = 'block';
        const a = document.createElement('a');
        a.href = url;
        a.download = 'tts.webm';
        a.click();
      };

      // Connect dummy oscillator to destination to keep stream alive
      oscillator.connect(dest);
      oscillator.start();

      recorder.start();

      // Speak using system audio (not captured, but keeps stream alive)
      synth.speak(utter);

      // Stop after estimated duration
      const duration = Math.min(10000, extractedText.length * 80);
      setTimeout(() => {
        recorder.stop();
        oscillator.stop();
      }, duration);
    });
  </script>
</body>
</html>
